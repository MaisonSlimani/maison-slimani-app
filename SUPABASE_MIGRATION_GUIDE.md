# üöÄ Guide de Migration Supabase vers un Nouveau Compte

Ce guide vous aidera √† migrer toutes vos donn√©es Supabase (base de donn√©es, storage, configurations) vers un nouveau compte Supabase.

## üìã Pr√©requis

1. **Nouveau compte Supabase** cr√©√© et projet initialis√©
2. **Supabase CLI** install√© (`npm install -g supabase`)
3. **Acc√®s aux deux comptes** (ancien et nouveau)
4. **psql** ou un client PostgreSQL pour les exports/imports

---

## üîç √âtape 1: Audit de votre Configuration Actuelle

### Ce que vous avez actuellement:

‚úÖ **Base de donn√©es:**
- Tables: `produits`, `commandes`, `admins`, `categories`, `settings`
- Migrations SQL (dans `supabase/migrations/`)
- Indexes (d√©finis dans les migrations)
- RLS Policies (Row Level Security)
- Fonctions RPC (comme `decrementer_stock`)
- Triggers et extensions

‚úÖ **Storage:**
- Bucket: `produits-images` (public)
- Fichiers/images des produits

‚úÖ **Realtime:**
- Abonnements aux changements de `commandes`

‚ùå **Edge Functions:** 
- D√©j√† migr√©es vers Vercel API Routes (pas besoin de migrer)

‚ùå **Supabase Auth:**
- Vous utilisez une authentification custom (table `admins`), pas Supabase Auth

---

## üì¶ √âtape 2: Exporter les Donn√©es de l'Ancien Compte

### 2.1 Exporter le Sch√©ma de la Base de Donn√©es

```bash
# Se connecter √† l'ancien projet Supabase
# R√©cup√©rer la connection string depuis: Settings ‚Üí Database ‚Üí Connection string
# Format: postgresql://postgres:[PASSWORD]@[HOST]:5432/postgres

# Exporter le sch√©ma (structure)
pg_dump -h [OLD_HOST] -U postgres -d postgres \
  --schema-only \
  --no-owner \
  --no-privileges \
  -f schema_export.sql

# Exporter les donn√©es
pg_dump -h [OLD_HOST] -U postgres -d postgres \
  --data-only \
  --no-owner \
  --no-privileges \
  -f data_export.sql

# Exporter TOUT (sch√©ma + donn√©es) - RECOMMAND√â
pg_dump -h [OLD_HOST] -U postgres -d postgres \
  --no-owner \
  --no-privileges \
  --clean \
  -f full_export.sql
```

**Alternative via Supabase Dashboard:**
1. Allez dans **Database** ‚Üí **Backups**
2. Cr√©ez un backup manuel
3. T√©l√©chargez le backup SQL

### 2.2 Exporter les Fichiers Storage

```bash
# Installer Supabase CLI si pas d√©j√† fait
npm install -g supabase

# Se connecter √† l'ancien projet
supabase login
supabase link --project-ref [OLD_PROJECT_REF]

# Cr√©er un script pour t√©l√©charger tous les fichiers
# Cr√©ez un fichier download-storage.js
```

**Script de t√©l√©chargement Storage:**

```javascript
// download-storage.js
const { createClient } = require('@supabase/supabase-js')
const fs = require('fs')
const path = require('path')

const OLD_SUPABASE_URL = process.env.OLD_SUPABASE_URL
const OLD_SUPABASE_SERVICE_KEY = process.env.OLD_SUPABASE_SERVICE_KEY
const DOWNLOAD_DIR = './storage-backup'

const supabase = createClient(OLD_SUPABASE_URL, OLD_SUPABASE_SERVICE_KEY)

async function downloadStorage() {
  // Cr√©er le dossier de backup
  if (!fs.existsSync(DOWNLOAD_DIR)) {
    fs.mkdirSync(DOWNLOAD_DIR, { recursive: true })
  }

  const bucketName = 'produits-images'
  const bucketDir = path.join(DOWNLOAD_DIR, bucketName)
  if (!fs.existsSync(bucketDir)) {
    fs.mkdirSync(bucketDir, { recursive: true })
  }

  // Lister tous les fichiers
  const { data: files, error } = await supabase.storage
    .from(bucketName)
    .list('', {
      limit: 1000,
      offset: 0,
    })

  if (error) {
    console.error('Erreur lors de la liste:', error)
    return
  }

  console.log(`Trouv√© ${files.length} fichiers √† t√©l√©charger`)

  // T√©l√©charger chaque fichier
  for (const file of files) {
    const { data, error: downloadError } = await supabase.storage
      .from(bucketName)
      .getPublicUrl(file.name)

    if (downloadError) {
      console.error(`Erreur pour ${file.name}:`, downloadError)
      continue
    }

    // T√©l√©charger le fichier
    const response = await fetch(data.publicUrl)
    const buffer = await response.arrayBuffer()
    const filePath = path.join(bucketDir, file.name)
    
    // Cr√©er les dossiers n√©cessaires
    const dir = path.dirname(filePath)
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true })
    }

    fs.writeFileSync(filePath, Buffer.from(buffer))
    console.log(`‚úÖ T√©l√©charg√©: ${file.name}`)
  }

  console.log('‚úÖ T√©l√©chargement termin√©!')
}

downloadStorage().catch(console.error)
```

**Ex√©cuter:**
```bash
# Ajouter les variables d'env
export OLD_SUPABASE_URL="https://[old-project-ref].supabase.co"
export OLD_SUPABASE_SERVICE_KEY="[old-service-role-key]"

# Ex√©cuter
node download-storage.js
```

---

## üöÄ √âtape 3: Importer dans le Nouveau Compte

### 3.1 Cr√©er le Nouveau Projet Supabase

1. Allez sur https://supabase.com/dashboard
2. Cr√©ez un nouveau projet
3. Notez le **Project Reference ID** et les **API Keys**

### 3.2 Importer le Sch√©ma et les Donn√©es

```bash
# R√©cup√©rer la connection string du nouveau projet
# Settings ‚Üí Database ‚Üí Connection string

# Importer le sch√©ma et les donn√©es
psql -h [NEW_HOST] -U postgres -d postgres -f full_export.sql

# OU via Supabase CLI
supabase db reset --db-url "postgresql://postgres:[PASSWORD]@[NEW_HOST]:5432/postgres"
```

**Alternative via Supabase Dashboard:**
1. Allez dans **SQL Editor**
2. Collez le contenu de `full_export.sql`
3. Ex√©cutez le script

### 3.3 Appliquer les Migrations (Optionnel mais Recommand√©)

Si vous pr√©f√©rez utiliser vos fichiers de migration:

```bash
# Lier le nouveau projet
supabase link --project-ref [NEW_PROJECT_REF]

# Appliquer toutes les migrations
supabase db push
```

### 3.4 V√©rifier les Tables et Donn√©es

```sql
-- V√©rifier que toutes les tables existent
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public'
ORDER BY table_name;

-- V√©rifier le nombre de lignes
SELECT 
  'produits' as table_name, COUNT(*) as count FROM produits
UNION ALL
SELECT 'commandes', COUNT(*) FROM commandes
UNION ALL
SELECT 'admins', COUNT(*) FROM admins
UNION ALL
SELECT 'categories', COUNT(*) FROM categories;
```

### 3.5 Importer les Fichiers Storage

**Cr√©er le bucket:**
```sql
-- Via SQL Editor dans Supabase Dashboard
INSERT INTO storage.buckets (id, name, public)
VALUES ('produits-images', 'produits-images', true);
```

**Script d'upload:**
```javascript
// upload-storage.js
const { createClient } = require('@supabase/supabase-js')
const fs = require('fs')
const path = require('path')

const NEW_SUPABASE_URL = process.env.NEW_SUPABASE_URL
const NEW_SUPABASE_SERVICE_KEY = process.env.NEW_SUPABASE_SERVICE_KEY
const STORAGE_DIR = './storage-backup/produits-images'

const supabase = createClient(NEW_SUPABASE_URL, NEW_SUPABASE_SERVICE_KEY)

async function uploadStorage() {
  // Lister tous les fichiers dans le dossier
  const files = getAllFiles(STORAGE_DIR)
  
  console.log(`Trouv√© ${files.length} fichiers √† uploader`)

  for (const filePath of files) {
    const relativePath = path.relative(STORAGE_DIR, filePath)
    const fileBuffer = fs.readFileSync(filePath)
    
    const { data, error } = await supabase.storage
      .from('produits-images')
      .upload(relativePath, fileBuffer, {
        contentType: getContentType(filePath),
        upsert: true
      })

    if (error) {
      console.error(`‚ùå Erreur pour ${relativePath}:`, error)
    } else {
      console.log(`‚úÖ Upload√©: ${relativePath}`)
    }
  }

  console.log('‚úÖ Upload termin√©!')
}

function getAllFiles(dir, fileList = []) {
  const files = fs.readdirSync(dir)
  files.forEach(file => {
    const filePath = path.join(dir, file)
    if (fs.statSync(filePath).isDirectory()) {
      getAllFiles(filePath, fileList)
    } else {
      fileList.push(filePath)
    }
  })
  return fileList
}

function getContentType(filePath) {
  const ext = path.extname(filePath).toLowerCase()
  const types = {
    '.jpg': 'image/jpeg',
    '.jpeg': 'image/jpeg',
    '.png': 'image/png',
    '.webp': 'image/webp',
    '.gif': 'image/gif'
  }
  return types[ext] || 'application/octet-stream'
}

uploadStorage().catch(console.error)
```

**Ex√©cuter:**
```bash
export NEW_SUPABASE_URL="https://[new-project-ref].supabase.co"
export NEW_SUPABASE_SERVICE_KEY="[new-service-role-key]"

node upload-storage.js
```

### 3.6 Configurer les RLS Policies

V√©rifiez que toutes les RLS policies sont bien appliqu√©es. Si elles ne sont pas dans votre export SQL, appliquez-les manuellement:

```sql
-- Exemple: V√©rifier les policies existantes
SELECT schemaname, tablename, policyname, permissive, roles, cmd, qual
FROM pg_policies
WHERE schemaname = 'public';
```

### 3.7 Activer Realtime

```sql
-- Activer Realtime pour la table commandes (si pas d√©j√† fait)
ALTER PUBLICATION supabase_realtime ADD TABLE commandes;
```

---

## üîß √âtape 4: Mettre √† Jour les Variables d'Environnement

### 4.1 Variables Locales (.env.local)

```bash
# Remplacer les anciennes valeurs
NEXT_PUBLIC_SUPABASE_URL=https://[new-project-ref].supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=[new-anon-key]
SUPABASE_SERVICE_ROLE_KEY=[new-service-role-key]
```

### 4.2 Variables Vercel

1. Allez sur https://vercel.com/dashboard
2. S√©lectionnez votre projet
3. **Settings** ‚Üí **Environment Variables**
4. Mettez √† jour:
   - `NEXT_PUBLIC_SUPABASE_URL`
   - `NEXT_PUBLIC_SUPABASE_ANON_KEY`
   - `SUPABASE_SERVICE_ROLE_KEY`
5. **Red√©ployez** votre application

---

## ‚úÖ √âtape 5: V√©rifications Finales

### 5.1 Tester la Base de Donn√©es

```bash
# Se connecter au nouveau projet
supabase link --project-ref [NEW_PROJECT_REF]

# Ouvrir Supabase Studio
supabase studio
```

V√©rifiez:
- ‚úÖ Toutes les tables existent
- ‚úÖ Les donn√©es sont pr√©sentes
- ‚úÖ Les indexes sont cr√©√©s
- ‚úÖ Les RLS policies sont actives

### 5.2 Tester le Storage

```bash
# V√©rifier que les fichiers sont accessibles
curl https://[new-project-ref].supabase.co/storage/v1/object/public/produits-images/[nom-fichier]
```

### 5.3 Tester l'Application

1. **Localement:**
   ```bash
   npm run dev
   ```
   - Testez l'affichage des produits
   - Testez l'upload d'images
   - Testez la cr√©ation de commandes

2. **En Production:**
   - V√©rifiez que Vercel utilise les nouvelles variables
   - Testez toutes les fonctionnalit√©s

---

## üõ†Ô∏è Scripts Automatis√©s

Cr√©ez un dossier `scripts/migration/` avec les scripts suivants:

### export-old-project.sh
```bash
#!/bin/bash
# Export complet de l'ancien projet

OLD_PROJECT_REF=$1
OLD_DB_PASSWORD=$2

echo "üì¶ Export de l'ancien projet..."

# Export DB
pg_dump -h db.$OLD_PROJECT_REF.supabase.co \
  -U postgres \
  -d postgres \
  --no-owner \
  --no-privileges \
  -f ./migration-backup/db_export.sql

echo "‚úÖ Export DB termin√©"
```

### import-new-project.sh
```bash
#!/bin/bash
# Import dans le nouveau projet

NEW_PROJECT_REF=$1
NEW_DB_PASSWORD=$2

echo "üöÄ Import dans le nouveau projet..."

# Import DB
psql -h db.$NEW_PROJECT_REF.supabase.co \
  -U postgres \
  -d postgres \
  -f ./migration-backup/db_export.sql

echo "‚úÖ Import DB termin√©"
```

---

## ‚ö†Ô∏è Points d'Attention

1. **Downtime:** Planifiez une fen√™tre de maintenance pour √©viter les pertes de donn√©es
2. **Backup:** Gardez toujours un backup de l'ancien projet pendant au moins 30 jours
3. **IDs:** Les IDs des enregistrements seront pr√©serv√©s si vous utilisez `pg_dump` complet
4. **Storage URLs:** Les URLs des images changeront, mais les chemins relatifs resteront identiques
5. **Realtime:** V√©rifiez que les abonnements Realtime fonctionnent correctement

---

## üìû Support

Si vous rencontrez des probl√®mes:
1. V√©rifiez les logs Supabase: **Logs** ‚Üí **Postgres Logs**
2. V√©rifiez les logs Vercel: **Deployments** ‚Üí **Functions Logs**
3. Consultez la documentation Supabase: https://supabase.com/docs

---

## ‚úÖ Checklist de Migration

- [ ] Export de la base de donn√©es (sch√©ma + donn√©es)
- [ ] Export des fichiers Storage
- [ ] Cr√©ation du nouveau projet Supabase
- [ ] Import de la base de donn√©es
- [ ] Cr√©ation du bucket Storage
- [ ] Upload des fichiers Storage
- [ ] V√©rification des RLS policies
- [ ] Activation de Realtime
- [ ] Mise √† jour des variables d'environnement (local)
- [ ] Mise √† jour des variables d'environnement (Vercel)
- [ ] Red√©ploiement sur Vercel
- [ ] Tests complets de l'application
- [ ] V√©rification des logs et monitoring
- [ ] Backup de l'ancien projet conserv√©

---

**Temps estim√©:** 2-4 heures selon la taille des donn√©es

**Difficult√©:** Moyenne

**Risque:** Faible si les √©tapes sont suivies correctement

